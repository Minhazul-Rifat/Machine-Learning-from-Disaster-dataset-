{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  Fare\n",
       "0         0       3    male  24.0  16.0\n",
       "1         0       3    male  18.0   8.0\n",
       "2         0       1    male  56.0  31.0\n",
       "3         0       3  female  25.0   8.0\n",
       "4         1       2  female  21.0  10.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', usecols=['Survived','Pclass','Sex','Age','Fare'])\n",
    "df = df.fillna(df.mean())\n",
    "df = df.round()\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nok\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\nok\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# first OHE the gender feature\n",
    "df = pd.get_dummies(df, columns=['Sex'])\n",
    "X = df.as_matrix(columns=['Pclass','Age','Sex_female','Sex_male','Fare'])\n",
    "Y = df.as_matrix(columns=['Survived'])\n",
    "# normalize age and fare\n",
    "X[:,1] = (X[:,1] - X[:,1].min())/(X[:,1].max() - X[:,1].min())\n",
    "X[:,4] = (X[:,4] - X[:,4].min())/(X[:,4].max() - X[:,4].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0, perplexity=15, n_iter=2000, n_iter_without_progress=1000)\n",
    "matrix_2d = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nok\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = df.as_matrix()\n",
    "# normalize age and fare\n",
    "data[:,2] = (data[:,2] - data[:,2].min())/(data[:,2].max() - data[:,2].min())\n",
    "data[:,3] = (data[:,3] - data[:,3].min())/(data[:,3].max() - data[:,3].min())\n",
    "X_train, X_test = train_test_split(data, test_size=0.1)\n",
    "Y_train = X_train[:,0] # first column is class\n",
    "Y_train = np.reshape(Y_train, newshape=(len(Y_train),1)) # reshape to a columns vector\n",
    "X_train = X_train[:,1:] # select all columns but class\n",
    "Y_test = X_test[:,0]\n",
    "Y_test = np.reshape(Y_test, newshape=(len(Y_test),1)) # reshape to a columns vector\n",
    "X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, deriv=False):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function\n",
    "    \"\"\"\n",
    "    if(deriv==True):\n",
    "        return (x*(1-x))\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x, deriv=False):\n",
    "    \"\"\"\n",
    "    Leaky ReLU activation function\n",
    "    \"\"\"\n",
    "    if deriv == True:\n",
    "        x[x<0] = 0.01\n",
    "        x[x>0] = 1.\n",
    "        return x\n",
    "    x[x<0] = 0.01*x[x<0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w0, w1, b1, b2):\n",
    "    \"\"\"\n",
    "    Function to predict an output given a data x, weight matrices w1 & w1 and biases b1 & b2\n",
    "    \"\"\"\n",
    "    A = np.dot(x,w0) + b1 # mXN X NxH +1xH ~ mxH\n",
    "    layer_1 = relu(A)\n",
    "    B = np.dot(layer_1,w1) + b2 # mxH X Hx1 ~ mx1 (preds)\n",
    "    layer_2 = B\n",
    "    return (sigmoid(layer_2) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x,y,i,batchSize=32):\n",
    "    \"\"\"\n",
    "    Function that returns a minibatch of a dataset\n",
    "    \"\"\"\n",
    "    return x[i:i+batchSize],y[i:i+batchSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Error: 0.47569181\n",
      "Epoch: 500, Error: 0.14825545\n",
      "Epoch: 1000, Error: 0.14123565\n",
      "Epoch: 1500, Error: 0.14745194\n"
     ]
    }
   ],
   "source": [
    "# learning rate, hidden layer dimension, dropout rate, batch size\n",
    "alpha, hidden_size, drop_rate, batch_size = (0.04,32,0.5,32)\n",
    "# randomly initialise synapses\n",
    "syn0 = 2*np.random.random((X_train.shape[1],hidden_size)) - 1 # NxH\n",
    "syn1 = 2*np.random.random((hidden_size,1)) - 1 # Hx1\n",
    "# randomly initialise biases\n",
    "b1 = np.random.randn(hidden_size) # 1xH\n",
    "b2 = np.random.randn(1) # 1x1\n",
    "avg_err = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    err = []\n",
    "\n",
    "    for i in range(int(X_train.shape[0]/batch_size)):\n",
    "\n",
    "        x,y = get_batch(X_train,Y_train,i,batch_size)\n",
    "\n",
    "        # Forward\n",
    "        layer_0 = x\n",
    "        A = np.dot(layer_0,syn0) + b1 # BxN X NxH ~ BxH\n",
    "        layer_1 = relu(A)\n",
    "        # drop out to reduce overfitting\n",
    "        layer_1 *= np.random.binomial([np.ones((len(x),hidden_size))],1-drop_rate)[0] * (1/(1-drop_rate))\n",
    "\n",
    "        B = np.dot(layer_1,syn1) + b2 # BxH X Hx1 ~ Bx1\n",
    "        layer_2 = sigmoid(B)\n",
    "\n",
    "        # Backprop\n",
    "        layer_2_error = layer_2 - y # Bx1\n",
    "        layer_2_delta = layer_2_error * sigmoid(layer_2,deriv=True) # Bx1 * Bx1 ~ Bx1\n",
    "\n",
    "        layer_1_error = np.dot(layer_2_delta,syn1.T) # Bx1 X 1xH ~ BxH\n",
    "        layer_1_delta = layer_1_error * relu(layer_1,deriv=True) # BxH * BxH ~ BxH\n",
    "\n",
    "        # update weights\n",
    "        syn1 -= alpha*np.dot(layer_1.T,layer_2_delta) # HxB X Bx1 ~ Hx1\n",
    "        syn0 -= alpha*np.dot(layer_0.T,layer_1_delta) # NxB X BxH ~ NxH\n",
    "\n",
    "        # update biases\n",
    "        m = len(y)\n",
    "        b2 -= alpha * (1.0 / m) * np.sum(layer_2_delta)\n",
    "        b1 -= alpha * (1.0 / m) * np.sum(layer_1_delta)\n",
    "\n",
    "        err.append(layer_2_error)\n",
    "\n",
    "    avg_err.append(np.mean( np.abs(err) ))\n",
    "    if epoch%500 == 0:\n",
    "        print(\"Epoch: %d, Error: %.8f\" % (epoch, np.mean( np.abs(err) )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.4019975031211"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on training set\n",
    "100*(1-np.sum(np.abs(predict(X_train, syn0, syn1, b1, b2) - Y_train))/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.11111111111111"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on test set\n",
    "100*(1-np.sum(np.abs(predict(X_test, syn0, syn1, b1, b2) - Y_test))/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
